{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA7oz5uGTMOJ"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n"
      ],
      "metadata": {
        "id": "MBN_2Z14Thzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Google Generative AI library\n",
        "!pip install google-generativeai\n",
        "\n",
        "# Import the library\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure with your Google API key\n",
        "GOOGLE_API_KEY = \"\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Create the model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Generate text\n",
        "prompt = \"Write a short poem about AI and web development.\"\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Print the output\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "I90DweGKTnJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Optional OpenAI import (used if OPENAI_API_KEY is set)\n",
        "try:\n",
        "    import openai\n",
        "    OPENAI_AVAILABLE = True\n",
        "except Exception:\n",
        "    OPENAI_AVAILABLE = False\n",
        "\n",
        "# CELL: Simple precedent dataset\n",
        "# Keep the dataset small for speed. In real usage, you'd index many case texts.\n",
        "PRECEDENTS = [\n",
        "    {\n",
        "        \"id\": \"SC-2017-RightToPrivacy\",\n",
        "        \"title\": \"Justice X v. Union of India (2017) - Right to Privacy\",\n",
        "        \"summary\": (\n",
        "            \"In 2017, the Supreme Court held that the Right to Privacy is a fundamental right under Article 21. \"\n",
        "            \"The judgment emphasized dignity, informational privacy, and the need to balance state interests against personal liberties. \"\n",
        "            \"The Court outlined a proportionality test and warned against unchecked state surveillance.\"\n",
        "        ),\n",
        "        \"year\": 2017,\n",
        "        \"court\": \"Supreme Court\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"HC-2019-DataRetention\",\n",
        "        \"title\": \"A. v. State (2019) - Data Retention Limits\",\n",
        "        \"summary\": (\n",
        "            \"High Court struck down a broad data retention law that required indefinite storage of telecom records. \"\n",
        "            \"Court held that retention must be limited in scope, time and purpose; safeguards and oversight required.\"\n",
        "        ),\n",
        "        \"year\": 2019,\n",
        "        \"court\": \"High Court\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"SC-2022-BiometricGuidelines\",\n",
        "        \"title\": \"R. v. Union (2022) - Biometric Guidelines clarified\",\n",
        "        \"summary\": (\n",
        "            \"Supreme Court clarified that biometric collection for targeted welfare schemes may be permissible with consent and safeguards. \"\n",
        "            \"However, mandatory universal biometric databases without judicial oversight were viewed skeptically.\"\n",
        "        ),\n",
        "        \"year\": 2022,\n",
        "        \"court\": \"Supreme Court\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# CELL: Embeddings + FAISS index builder\n",
        "EMBED_MODEL_NAME = 'all-MiniLM-L6-v2'  # compact and fast\n",
        "\n",
        "class Retriever:\n",
        "    def __init__(self, precedents: List[Dict[str, Any]], model_name: str = EMBED_MODEL_NAME):\n",
        "        self.precedents = precedents\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.ids = [p['id'] for p in precedents]\n",
        "        # Build embeddings\n",
        "        texts = [p['summary'] for p in precedents]\n",
        "        print('Computing embeddings for precedents...')\n",
        "        self.embeddings = self.model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "        # Normalize\n",
        "        faiss.normalize_L2(self.embeddings)\n",
        "        d = self.embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatIP(d)  # inner product -> cosine when normalized\n",
        "        self.index.add(self.embeddings)\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 3):\n",
        "        q_emb = self.model.encode([query], convert_to_numpy=True)\n",
        "        faiss.normalize_L2(q_emb)\n",
        "        D, I = self.index.search(q_emb, k)\n",
        "        results = []\n",
        "        for idx in I[0]:\n",
        "            if idx < 0 or idx >= len(self.precedents):\n",
        "                continue\n",
        "            results.append(self.precedents[idx])\n",
        "        return results\n",
        "\n",
        "# CELL: Simple agentic pipeline\n",
        "@dataclass\n",
        "class Evidence:\n",
        "    precedent_id: str\n",
        "    text: str\n",
        "    year: int\n",
        "    court: str\n",
        "\n",
        "class LegalAgent:\n",
        "    def __init__(self, retriever: Retriever):\n",
        "        self.retriever = retriever\n",
        "\n",
        "    def evidence_check(self, query: str) -> List[Evidence]:\n",
        "        # Retrieve and map to Evidence objects\n",
        "        docs = self.retriever.retrieve(query, k=3)\n",
        "        return [Evidence(precedent_id=d['id'], text=d['summary'], year=d['year'], court=d['court']) for d in docs]\n",
        "\n",
        "    def call_llm(self, prompt: str, max_tokens: int = 512) -> str:\n",
        "        # Use OpenAI if available and key set, else fallback to simulated reasoner\n",
        "        key = os.environ.get('OPENAI_API_KEY')\n",
        "        if key and OPENAI_AVAILABLE:\n",
        "            openai.api_key = key\n",
        "            resp = openai.ChatCompletion.create(\n",
        "                model='gpt-4o-mini' if 'gpt-4o-mini' in openai.Model.list() else 'gpt-4o',\n",
        "                messages=[{\"role\": \"system\", \"content\": \"You are a legal reasoning assistant.\"},\n",
        "                          {\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=0.2\n",
        "            )\n",
        "            txt = resp['choices'][0]['message']['content']\n",
        "            return txt\n",
        "        else:\n",
        "            # Simulated LLM: produce a structured output using templates (fast & offline)\n",
        "            return simulated_reasoner(prompt)\n",
        "\n",
        "    def run(self, case_description: str) -> Dict[str, Any]:\n",
        "        # Agent steps:\n",
        "        # 1. Retrieve precedents\n",
        "        evidence = self.evidence_check(case_description)\n",
        "        # 2. Build prompt with retrieved evidence and instructions for multi-step reasoning\n",
        "        prompt = build_prompt(case_description, evidence)\n",
        "        # 3. Call LLM\n",
        "        llm_out = self.call_llm(prompt)\n",
        "        # 4. Parse output (we'll keep it simple and return raw)\n",
        "        return {\n",
        "            'evidence': [e.__dict__ for e in evidence],\n",
        "            'prompt': prompt,\n",
        "            'llm_output': llm_out\n",
        "        }\n",
        "\n",
        "# CELL: Prompt builder and simulated reasoner\n",
        "\n",
        "def build_prompt(case_description: str, evidence: List[Evidence]) -> str:\n",
        "    evid_text = \"\\n\\n\".join([f\"[{e.precedent_id}] {e.text} ({e.court}, {e.year})\" for e in evidence])\n",
        "    prompt = (\n",
        "        \"You are asked to reason about a legal case.\\n\"\n",
        "        \"Case description:\\n\" + case_description + \"\\n\\n\"\n",
        "        \"Relevant precedents:\\n\" + evid_text + \"\\n\\n\"\n",
        "        \"Task:\\n\"\n",
        "        \"1) Summarize the most relevant points of law from the precedents.\\n\"\n",
        "        \"2) Provide legal arguments in favor of the petitioner (privacy breach).\\n\"\n",
        "        \"3) Provide legal arguments in favor of the government (state interest).\\n\"\n",
        "        \"4) Assess the likely verdict and explain the reasoning, using a proportionality test if appropriate.\\n\"\n",
        "        \"5) List any recommended safeguards or modifications to the policy to make it constitutional.\\n\\n\"\n",
        "        \"Answer in numbered sections. Be concise and cite precedents by their id when used.\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def simulated_reasoner(prompt: str) -> str:\n",
        "    # A crude template-based responder: extracts keywords and crafts answers.\n",
        "    # This is only a fallback to make the notebook runnable without an API key.\n",
        "    # It does NOT match an LLM's depth but is useful for demos.\n",
        "    out = []\n",
        "    out.append(\"1) Precedent summary:\\n- 2017 Right to Privacy: Privacy is fundamental under Article 21; proportionality required.\\n- 2019 Data Retention: retention limited by scope/time/purpose.\\n- 2022 Biometric Guidelines: biometric collection may be permissible with consent & safeguards, but universal mandatory databases are risky.\")\n",
        "    out.append(\"\\n2) Arguments for petitioner:\\n- Mandatory biometric submission is an intrusion into informational privacy (cite SC-2017-RightToPrivacy).\\n- Policy fails proportionality: it's overbroad and not the least restrictive means.\\n- Lack of sufficient safeguards and oversight (cite HC-2019-DataRetention).\")\n",
        "    out.append(\"\\n3) Arguments for government:\\n- Biometric data improves efficient delivery of services and reduces fraud.\\n- If policy contains strong safeguards, oversight and limited retention, it could be constitutional in part (cite SC-2022-BiometricGuidelines).\\n- State interest in public welfare and efficient administration is legitimate.\")\n",
        "    out.append(\"\\n4) Likely verdict:\\n- Court may strike down or read-down the policy as applied universally and mandatorily. A permissible variant would be: limited scope, explicit safeguards, independent oversight, and retention limits.\\n- The proportionality test likely favors privacy unless government demonstrates strict necessity and narrow tailoring.\")\n",
        "    out.append(\"\\n5) Suggested safeguards:\\n- Purpose limitation, data minimization, retention schedules, independent oversight, encryption and breach notifications, opt-out/consent where feasible, judicial review.\" )\n",
        "    return \"\\n\\n\".join(out)\n",
        "\n",
        "# CELL: Example usage\n",
        "if __name__ == '__main__':\n",
        "    print('Initializing retriever and agent...')\n",
        "    retr = Retriever(PRECEDENTS)\n",
        "    agent = LegalAgent(retr)\n",
        "\n",
        "    case_2025 = (\n",
        "        \"In 2025, the government issues a policy mandating that all citizens must submit biometric data (fingerprints and iris scans) \"\n",
        "        \"to access public services such as welfare disbursement and government IDs. The petitioner claims this violates their fundamental right to privacy under Article 21.\"\n",
        "    )\n",
        "\n",
        "    result = agent.run(case_2025)\n",
        "\n",
        "    print('\\n===== Evidence retrieved =====')\n",
        "    for e in result['evidence']:\n",
        "        print(f\"- {e['precedent_id']}: {e['text'][:140]}...\")\n",
        "\n",
        "    print('\\n===== LLM Output =====')\n",
        "    print(result['llm_output'])\n",
        "\n",
        "    print('\\n===== Notes =====')\n",
        "    print('If you want more thorough legal-style outputs, set your OPENAI_API_KEY and re-run.\\n')\n",
        "    print('To save outputs to files or push to GitHub, you can write result to JSON and commit to your repo.')\n",
        "\n",
        "    # Example: save result\n",
        "    with open('hannoworks_result_example.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(result, f, indent=2)\n",
        "\n",
        "    print('Saved example output to hannoworks_result_example.json')"
      ],
      "metadata": {
        "id": "Km0WugnPTdvr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}